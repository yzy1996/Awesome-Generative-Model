





### predict camera pose from image

在nerf里也有

更早的领域里









novel view synthesis











表征学习和生成模型的关系：

表征学习是找到一种低维表征，

生成是靠表征的

convolutions 到表征， deconvolutions 是生成



所以划分为：大的是生成模型，因为这是我们的目的，里面包含了2D的表征，3D的表征等方法



表征肯定是伴随着重建的，因为表征好坏怎么评估呢，就是靠重建





生成模型主要又是GAN AE 这些



2D 的

3D 的



那么 neural rendering 算什么呢





## 新视角的生成，如果能3D重建，是不是肯定就能生成新视角，

## 变形：是为了做什么呢



### 3D 表征和重建

：传统方法和新方法

重建了之后又还最好能还原回去2D，这一过程可以被看成是

### rendering

需要 viewpoint ，所以如何从2D 图像中获得 viewpoint 信息很关键





### 3D 生成



多角度的生成，就有新角度，有2D 3D的

但这里3D的又会表征那里有重复



生成模型里的其他领域

：文本，语音



为什么要研究这些生成：



利用CG图像结合一些VR技术，可以让我们在有限的距离里遨游世界



变形

： 动作变换，人脸图片变换，



可控是和解耦相关的



条件conditional 是和变形相关的



conditional control



逆向又是一个大类



根据方法划分



域的迁移



形状相关性





根据任务划分：

- pose 生成 pose generation
- 图像动起来 image animation
- 
- 



还有一些通用的基础知识：

- Distance Metric





一个大的分类其实是：

数据集只有2D的，生成3D的，3D 的和什么又是一致的呢？

多视角；新视角；

而建模整个3D模型，需要哪些信息呢？ -> camera viewpoint, object pose, object entities



可以被一个名词所涵盖：3D scene properties

we want to control: camera viewpoint, 3D pose, shape and appearance, multiple objects





## Single-View 3D Reconstruction

划分为：3D supervised| 2D supervised | unsupervised 



3D attributes, including camera, shape, texture, and light



重建什么？object's shape and texture

只需要一张图片吗？不，还需要2D image-level annotation

方法的发展进步：

- fit the parameters of a 3D prior morphable model (3DMM)

> building these prior models is expensive and time-consuming

- deep model 3D supervised reconstruction

> 需要3D ground truth, attributes or annotation

- 2D supervised reconstruction

> key modules is a differentiable render 





这里面又可以细分，category-specific 和 general 的





## novel view synthesis from 2D images

简称 NVS，他所要解决的问题是，从一些离散的观测中（不同视角的少量一些图片）



NVS techniques：可以先分成好几类

- explicitly reconstruction 

  只去构建表面

  然后这些方法无法生成高保真的结果

- volume-based representation 

相关工作有：Local Light Field Fusion， NeRF，Soft 3D Reconstruction for View Synthesis， SRN，Stereo Magnification: Learning View Synthesis using Multiplane Images

  model了整个空间，并且用volume rendering的方法生成图片

  这样带来的好处是：全局是连续的，都有了梯度，连续也可以高保真，

Neural Radiance Field (NeRF)



现存的一些方法是需要 每张图片的相机的参数，这个参数可以来自于

- 训练数据就有

- 通过一些技术估计 （例如 Structure-from-Motion）COLMAP

  



所以来了，怎么真正纯粹地只从RGB图像中生成呢？

- NeRF--



