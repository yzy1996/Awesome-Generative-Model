# Few-Shot & Limited Data



## Introduction

On the one hand, we can utilize **transfer learning** with a pre-trained model.

On the other hand, we can 

Dynamic data-augmentation







## Literature

[fastgan](#fastgan)

[DiffAugment](#DiffAugment)

---

[Training Generative Adversarial Networks with Limited Data](https://arxiv.org/abs/2006.06676)  
**[`NeurIPS 2020`]** **(`NVIDIA`)** [[:octocat:](https://github.com/NVlabs/stylegan2-ada)] (*Tero Karras, Timo Aila*)

<details><summary>Click to expand</summary><p>


**Summary**

> Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge




</p></details>

---

<span id="DiffAugment"></span>[Differentiable augmentation for data-efficient gan training](https://arxiv.org/pdf/2006.10738.pdf)  
**[`NeurIPS 2020`]** **(`MIT`)** [[:octocat:](https://github.com/mit-han-lab/data-efficient-gans)] (*Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, Song Han*)



---

<span id="Fastgan"></span>[Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis](https://arxiv.org/pdf/2101.04775.pdf)  
**[`ICLR 2021`]** **(`Rutgers`)** [[:octocat:](https://github.com/odegeasslbc/FastGAN-pytorch)] (*Bingchen Liu, Yizhe Zhu, Kunpeng Song, Ahmed Elgammal*)

<details><summary>Click to expand</summary><p>


**Summary**

> Use a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder.

</p></details>

---



<span id="InsGen"></span>
Data-Efficient Instance Generation from Instance Discrimination  
**[Arxiv 2021] (CUHK, Byte)**  
*Ceyuan Yang, Yujun Shen, Yinghao Xu, Bolei Zhou*

<details><summary>Click to expand</summary><p>

![image-20210626205841547](https://raw.githubusercontent.com/yzy1996/Image-Hosting/master/20210626205849.png)

> Details




</p></details>

---